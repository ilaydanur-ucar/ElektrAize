# anomaly_api.py
# -*- coding: utf-8 -*-
"""
ElektrAize Anomaly API - Tam Ã‡alÄ±ÅŸan Versiyon
"""
from typing import List, Optional, Dict, Any
import numpy as np
import pandas as pd
from fastapi import FastAPI, Query, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sklearn.ensemble import RandomForestRegressor
import warnings
warnings.filterwarnings('ignore')

from firebase_auth import get_current_user
from typing import Dict

from veri_cek import (
    get_train_test,         
    get_processed_frames,   
    DATE_COL, CITY_COL
)


# -----------------------------------------------------------------------------
# FastAPI kurulum
# -----------------------------------------------------------------------------
app = FastAPI(title="ElektrAize Anomaly API", version="3.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

# -----------------------------------------------------------------------------
# Data Modeller
# -----------------------------------------------------------------------------
class AnomalyItem(BaseModel):
    sehir: str
    donem: str
    gercek: float
    tahmin: float
    residual: float
    anomali: bool
    baseline: Optional[float] = None
    dev_pct: Optional[float] = None
    alt_limit: Optional[float] = None
    ust_limit: Optional[float] = None
    category: Optional[str] = None

# TÃ¼m tÃ¼ketim kategorileri - BOÅžLUKSUZ ve DOÄžRU
CONSUMPTION_CATEGORIES = {
    "genel": "Genel_Toplam_MWh",
    "aydinlatma": "Aydinlatma_MWh", 
    "mesken": "Mesken_MWh",
    "sanayi": "Sanayi_MWh",
    "tarimsal": "TarÄ±msal_Sulama_MWh",
    "ticarethane": "Ticarethane_MWh",
    "diger": "Diger_MWh"
}

# Global model dictionary
MODELS = {}

# -----------------------------------------------------------------------------
# MODEL YÃœKLEME - GELÄ°ÅžTÄ°RÄ°LMÄ°Åž
# -----------------------------------------------------------------------------
def load_all_models():
    """TÃ¼m kategoriler iÃ§in model yÃ¼kle - GeliÅŸtirilmiÅŸ versiyon"""
    global MODELS
    
    for category_name, target_col in CONSUMPTION_CATEGORIES.items():
        try:
            print(f"\n[MODEL] {category_name} iÃ§in model yÃ¼kleniyor...")
            print(f"[MODEL] Target column: {target_col}")
            
            # Veri kontrolÃ¼
            Xtr, Xte, ytr, yte = get_train_test(target_col=target_col)
            
            print(f"[MODEL] Veri boyutlarÄ± - Xtr: {Xtr.shape}, Xte: {Xte.shape}")
            
            if len(Xtr) == 0 or len(Xte) == 0:
                print(f"[UYARI] {category_name} iÃ§in yeterli veri yok, atlanÄ±yor...")
                MODELS[category_name] = None
                continue
            
            model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            
            model.fit(Xtr, ytr)
            
            # Model baÅŸarÄ±sÄ±nÄ± kontrol et
            train_score = model.score(Xtr, ytr)
            test_score = model.score(Xte, yte) if len(Xte) > 0 else 0
            
            MODELS[category_name] = {
                'model': model,
                'target_col': target_col,
                'train_score': train_score,
                'test_score': test_score
            }
            
            print(f"[OK] {category_name} modeli yÃ¼klendi - Train RÂ²: {train_score:.3f}, Test RÂ²: {test_score:.3f}")
            
        except Exception as e:
            print(f"[ERROR] {category_name} modeli yÃ¼klenemedi: {str(e)}")
            MODELS[category_name] = None

# -----------------------------------------------------------------------------
# ANOMALÄ° TESPÄ°TÄ° - GELÄ°ÅžTÄ°RÄ°LMÄ°Åž
# -----------------------------------------------------------------------------
def detect_anomalies(gercek: pd.Series, baseline: pd.Series, tolerance_pct: float = 0.10):
    """GeliÅŸtirilmiÅŸ anomali tespiti"""
    # Baseline sÄ±fÄ±r deÄŸerlerini Ã¶nle
    baseline_safe = baseline.replace(0, 1e-8)
    
    alt_limit = baseline_safe * (1 - tolerance_pct)
    ust_limit = baseline_safe * (1 + tolerance_pct)
    
    anomalies = ((gercek < alt_limit) | (gercek > ust_limit)) & baseline.notna()
    return anomalies, alt_limit, ust_limit

# -----------------------------------------------------------------------------
# ENDPOINT'LER - TAMAMEN YENÄ°LENDÄ°
# -----------------------------------------------------------------------------
@app.on_event("startup")
async def startup_event():
    """Uygulama baÅŸladÄ±ÄŸÄ±nda tÃ¼m modelleri yÃ¼kle"""
    print("\n" + "="*60)
    print("[STARTUP] TÃ¼m modeller yÃ¼kleniyor...")
    print("="*60)
    
    load_all_models()
    
    loaded_count = sum(1 for m in MODELS.values() if m is not None)
    print(f"\n[STARTUP] {loaded_count}/{len(CONSUMPTION_CATEGORIES)} model yÃ¼klendi")
    
    # YÃ¼klenen modelleri gÃ¶ster
    for category, model_info in MODELS.items():
        status = "YÃœKLENDÄ°" if model_info is not None else "YÃœKLENMEDÄ°"
        if model_info:
            print(f"  âœ“ {category}: RÂ²={model_info.get('train_score', 0):.3f}")
        else:
            print(f"  âœ— {category}: Model yÃ¼klenemedi")

@app.get("/")
def read_root():
    loaded_count = sum(1 for m in MODELS.values() if m is not None)
    return {
        "message": "ElektrAize Multi-Category Anomaly API",
        "version": "3.0",
        "available_categories": list(CONSUMPTION_CATEGORIES.keys()),
        "models_loaded": f"{loaded_count}/{len(CONSUMPTION_CATEGORIES)}",
        "status": "ready"
    }

@app.get("/health")
def health():
    loaded_count = sum(1 for m in MODELS.values() if m is not None)
    return {
        "status": "ok" if loaded_count > 0 else "error",
        "loaded_models": loaded_count,
        "total_categories": len(CONSUMPTION_CATEGORIES),
        "available_categories": [cat for cat, model in MODELS.items() if model is not None]
    }

@app.get("/categories")
def get_categories():
    """TÃ¼m kategorileri listele"""
    loaded_models = {cat: (model is not None) for cat, model in MODELS.items()}
    loaded_details = {}
    
    for cat, model_info in MODELS.items():
        if model_info:
            loaded_details[cat] = {
                "loaded": True,
                "train_score": model_info.get('train_score', 0),
                "test_score": model_info.get('test_score', 0),
                "target_column": model_info.get('target_col', '')
            }
        else:
            loaded_details[cat] = {"loaded": False}
    
    return {
        "available_categories": list(CONSUMPTION_CATEGORIES.keys()),
        "models_loaded": loaded_models,
        "details": loaded_details
    }

@app.get("/anomalies", response_model=List[AnomalyItem])
def anomalies(
    category: str = Query("genel", description="TÃ¼ketim kategorisi"),
    city: Optional[str] = Query(None, description="Åžehir adÄ± (BÃœYÃœK HARF ve Ä°ngilizce karakterlerle)"),
    start: Optional[str] = Query(None, description="YYYY-MM-DD"),
    end: Optional[str] = Query(None, description="YYYY-MM-DD"),
    tolerance_pct: float = Query(0.10, description="Tolerans yÃ¼zdesi"),
    debug: bool = Query(False, description="Debug bilgilerini gÃ¶ster"),
    current_user: Dict = Depends(get_current_user)  # Bu satÄ±rÄ± ekliyoruz
):
    """
    GELÄ°ÅžTÄ°RÄ°LMÄ°Åž ANOMALÄ° TESPÄ°TÄ°
    - Kategori adÄ± boÅŸluk kontrolÃ¼
    - DetaylÄ± hata yÃ¶netimi  
    - GeliÅŸtirilmiÅŸ debug modu
    """
    try:
      
        # Kategori adÄ±nÄ± temizle (baÅŸtaki/sondaki boÅŸluklarÄ± kaldÄ±r)
        category = category.strip().lower()
        
        print(f"\n[ANOMALI] Yeni istek - Kategori: '{category}', Åžehir: {city}")
        
         # Model kontrolÃ¼ - TEMÄ°ZLENMÄ°Åž category Ä°LE KONTROL ET
        if category not in MODELS or MODELS[category] is None:
            available_cats = [cat for cat, model in MODELS.items() if model is not None]
            raise HTTPException(
                status_code=400, 
                detail=f"'{category}' kategorisi iÃ§in model yÃ¼klenmemiÅŸ. Mevcut kategoriler: {available_cats}"
            )
        
        # ... KODUN GERÄ° KALANI AYNEN KALACAK ...
        model_info = MODELS[category]
        target_col = model_info['target_col']
        model = model_info['model']
        
        print(f"[MODEL] {category} modeli kullanÄ±lÄ±yor - Target: {target_col}")

        # Verileri yÃ¼kle
        df_train, df_test = get_processed_frames(target_col=target_col)
        # ... mevcut kodun geri kalanÄ± AYNEN kalacak ...

        # Model kontrolÃ¼ - geliÅŸtirilmiÅŸ
        if category not in CONSUMPTION_CATEGORIES:
            available_cats = list(CONSUMPTION_CATEGORIES.keys())
            raise HTTPException(
                status_code=400, 
                detail=f"'{category}' kategorisi bulunamadÄ±. Mevcut kategoriler: {available_cats}"
            )
        
        if category not in MODELS or MODELS[category] is None:
            available_cats = [cat for cat, model in MODELS.items() if model is not None]
            raise HTTPException(
                status_code=400, 
                detail=f"'{category}' kategorisi iÃ§in model yÃ¼klenmemiÅŸ. Mevcut kategoriler: {available_cats}"
            )
        
        model_info = MODELS[category]
        target_col = model_info['target_col']
        model = model_info['model']
        
        print(f"[MODEL] {category} modeli kullanÄ±lÄ±yor - Target: {target_col}")

        # Verileri yÃ¼kle
        df_train, df_test = get_processed_frames(target_col=target_col)
        Xtr, Xte, ytr, yte = get_train_test(target_col=target_col)
        
        if debug:
            print(f"[DEBUG] Veri boyutlarÄ± - Train: {df_train.shape}, Test: {df_test.shape}")
            print(f"[DEBUG] X_train: {Xtr.shape}, X_test: {Xte.shape}, y_test: {yte.shape}")
            if CITY_COL in df_test.columns:
                cities_in_test = df_test[CITY_COL].unique()
                print(f"[DEBUG] Test verisindeki ÅŸehir sayÄ±sÄ±: {len(cities_in_test)}")
                print(f"[DEBUG] Ä°lk 10 ÅŸehir: {cities_in_test[:10]}")
                if city:
                    city_data = df_test[df_test[CITY_COL] == city]
                    print(f"[DEBUG] '{city}' ÅŸehri iÃ§in kayÄ±t sayÄ±sÄ±: {len(city_data)}")

        # Baseline hesapla
        df_train = df_train.copy()
        df_train["ay"] = pd.to_datetime(df_train[DATE_COL]).dt.month
        seasonal_baseline = (
            df_train.groupby([CITY_COL, "ay"])[target_col]
            .mean()
            .rename("baseline")
            .reset_index()
        )

        # Test verisine baseline'Ä± ekle
        df_test = df_test.copy()
        df_test["ay"] = pd.to_datetime(df_test[DATE_COL]).dt.month
        df_test = df_test.merge(seasonal_baseline, on=[CITY_COL, "ay"], how="left")

        # Model tahminleri
        yhat = model.predict(Xte)
        
        # Verileri hazÄ±rla - index uyumluluÄŸu iÃ§in
        df_test_reset = df_test.reset_index(drop=True)
        min_len = min(len(df_test_reset), len(yte), len(yhat))
        
        df_test_ordered = df_test_reset.head(min_len).copy()
        yte_series = pd.Series(yte.values[:min_len])
        yhat_series = pd.Series(yhat[:min_len])
        baseline_series = df_test_ordered["baseline"].reset_index(drop=True)

        print(f"[ISLENEN] {category} - {min_len} kayÄ±t iÅŸlendi")

        # Anomali tespiti
        flags_anomali, alt_limit, ust_limit = detect_anomalies(
            yte_series, baseline_series, tolerance_pct
        )

        # SonuÃ§larÄ± hazÄ±rla
        out = pd.DataFrame({
            "sehir": df_test_ordered[CITY_COL].astype(str),
            "donem": pd.to_datetime(df_test_ordered[DATE_COL]).dt.strftime("%Y-%m-%d"),
            "gercek": yte_series.astype(float),
            "tahmin": yhat_series.astype(float),
            "residual": (yte_series - yhat_series).astype(float),
            "anomali": flags_anomali.astype(bool),
            "baseline": baseline_series.astype(float),
            "dev_pct": ((yte_series - baseline_series) / baseline_series.replace(0, 1e-8)).astype(float),
            "alt_limit": alt_limit.astype(float),
            "ust_limit": ust_limit.astype(float),
            "category": category
        })

        # Filtreleme - GELÄ°ÅžTÄ°RÄ°LMÄ°Åž
        original_count = len(out)
        filtered_count = original_count
        
        if city:
            # BÃ¼yÃ¼k harf tam eÅŸleÅŸme
            city_mask = out["sehir"] == city
            filtered_out = out[city_mask]
            filtered_count = len(filtered_out)
            
            print(f"[FILTRE] Åžehir: '{city}' -> {filtered_count} kayÄ±t (Ã¶nce: {original_count})")
            
            # EÄŸer hiÃ§ kayÄ±t yoksa, ÅŸehir ismini kontrol et
            if filtered_count == 0:
                available_cities = sorted(out["sehir"].unique()) if original_count > 0 else []
                similar_cities = [c for c in available_cities if city.upper() in c.upper()] if available_cities else []
                
                print(f"[UYARI] '{city}' ÅŸehri bulunamadÄ±!")
                print(f"[UYARI] Mevcut ÅŸehirler ({len(available_cities)}): {available_cities[:10]}{'...' if len(available_cities) > 10 else ''}")
                if similar_cities:
                    print(f"[UYARI] Benzer ÅŸehirler: {similar_cities}")
                
                # Benzer ÅŸehir Ã¶nerisi yap
                if similar_cities:
                    raise HTTPException(
                        status_code=400,
                        detail=f"'{city}' ÅŸehri bulunamadÄ±. Benzer ÅŸehirler: {similar_cities[:3]}"
                    )
                else:
                    raise HTTPException(
                        status_code=400,
                        detail=f"'{city}' ÅŸehri bulunamadÄ±. Mevcut ÅŸehirler: {available_cities[:5]}..."
                    )
            else:
                out = filtered_out

        if start:
            start_date = pd.to_datetime(start).strftime("%Y-%m-%d")
            out = out[out["donem"] >= start_date]
            print(f"[FILTRE] BaÅŸlangÄ±Ã§ tarihi: {start} -> {len(out)} kayÄ±t")
            
        if end:
            end_date = pd.to_datetime(end).strftime("%Y-%m-%d")
            out = out[out["donem"] <= end_date]
            print(f"[FILTRE] BitiÅŸ tarihi: {end} -> {len(out)} kayÄ±t")

        # Ä°STATÄ°STÄ°KLER
        total_records = len(out)
        anomaly_count = out["anomali"].sum()
        anomaly_ratio = anomaly_count / total_records if total_records > 0 else 0
        
        print("=" * 60)
        print(f"[SONUÃ‡] Kategori: {category.upper()}")
        print(f"[SONUÃ‡] Åžehir: {city if city else 'TÃœM ÅžEHÄ°RLER'}")
        print(f"[SONUÃ‡] Toplam kayÄ±t: {total_records}")
        print(f"[SONUÃ‡] Anomali sayÄ±sÄ±: {anomaly_count}")
        print(f"[SONUÃ‡] Anomali oranÄ±: %{anomaly_ratio*100:.1f}")
        print(f"[SONUÃ‡] Tolerans: %{tolerance_pct*100:.1f}")
        
        if total_records == 0:
            print("[UYARI] HiÃ§ kayÄ±t kalmadÄ±! Filtreleri kontrol edin.")
        
        # Ä°lk birkaÃ§ anomaliyi gÃ¶ster
        anomalies_df = out[out['anomali']]
        if len(anomalies_df) > 0:
            print(f"[ANOMALI] {len(anomalies_df)} anomali bulundu:")
            for i, row in anomalies_df.head(3).iterrows():
                print(f"  ðŸ“ {row['sehir']} - {row['donem']}: GerÃ§ek: {row['gercek']:.0f}, Sapma: %{row['dev_pct']*100:.1f}")
        else:
            print("[UYARI] HiÃ§ anomali bulunamadÄ±!")
        print("=" * 60)

        # SonuÃ§larÄ± dÃ¶ndÃ¼r
        result = [AnomalyItem(**rec) for rec in out.to_dict(orient="records")]
        
        # Debug modunda ekstra bilgi
        if debug:
            debug_info = {
                "category": category,
                "city": city,
                "total_processed": min_len,
                "after_filters": len(out),
                "anomalies_found": anomaly_count,
                "anomaly_ratio": f"{anomaly_ratio*100:.1f}%",
                "tolerance_pct": tolerance_pct,
                "available_cities_sample": sorted(df_test[CITY_COL].unique().tolist())[:10] if CITY_COL in df_test.columns else [],
                "date_range": {
                    "min": out["donem"].min() if len(out) > 0 else None,
                    "max": out["donem"].max() if len(out) > 0 else None
                }
            }
            
            # Debug modu iÃ§in Ã¶zel response
            from fastapi.responses import JSONResponse
            return JSONResponse({
                "data": [item.dict() for item in result],
                "debug_info": debug_info
            })
        
        return result

    except HTTPException:
        raise
    except Exception as e:
        error_msg = f"Anomali tespiti sÄ±rasÄ±nda hata: {str(e)}"
        print(f"[ERROR] {error_msg}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=error_msg)

@app.get("/debug/city/{city_name}")
def debug_city_data(city_name: str):
    """Belirli bir ÅŸehrin verilerini kontrol et"""
    try:
        # TÃ¼m kategorilerde bu ÅŸehri ara
        results = {}
        
        for category, target_col in CONSUMPTION_CATEGORIES.items():
            try:
                df_train, df_test = get_processed_frames(target_col=target_col)
                
                # BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf duyarsÄ±z arama
                city_upper = city_name.upper()
                
                # Åžehri bul
                in_train = city_upper in [city.upper() for city in df_train[CITY_COL].dropna().unique()] if CITY_COL in df_train.columns else False
                in_test = city_upper in [city.upper() for city in df_test[CITY_COL].dropna().unique()] if CITY_COL in df_test.columns else False
                
                # EÄŸer test'te varsa, veri sayÄ±larÄ±nÄ± al
                test_records = 0
                train_records = 0
                test_dates = []
                target_values = []
                
                if in_test and CITY_COL in df_test.columns:
                    test_data = df_test[df_test[CITY_COL].str.upper() == city_upper]
                    test_records = len(test_data)
                    if DATE_COL in test_data.columns:
                        test_dates = test_data[DATE_COL].dt.strftime('%Y-%m-%d').unique().tolist()
                    if target_col in test_data.columns:
                        target_values = test_data[target_col].tolist()
                
                if in_train and CITY_COL in df_train.columns:
                    train_data = df_train[df_train[CITY_COL].str.upper() == city_upper]
                    train_records = len(train_data)
                
                results[category] = {
                    "in_train": in_train,
                    "in_test": in_test,
                    "test_records": test_records,
                    "train_records": train_records,
                    "test_dates": test_dates[:5],  # Ä°lk 5 tarih
                    "target_values_sample": target_values[:5]  # Ä°lk 5 deÄŸer
                }
                    
            except Exception as e:
                results[category] = {"error": str(e)}
        
        # TÃ¼m kategorilerde toplam
        total_test_records = sum(r["test_records"] for r in results.values() if isinstance(r, dict) and "test_records" in r)
        total_train_records = sum(r["train_records"] for r in results.values() if isinstance(r, dict) and "train_records" in r)
        
        return {
            "searched_city": city_name,
            "city_upper": city_name.upper(),
            "summary": {
                "total_test_records": total_test_records,
                "total_train_records": total_train_records,
                "categories_with_data": [cat for cat, res in results.items() if isinstance(res, dict) and res.get("test_records", 0) > 0]
            },
            "results": results
        }
        
    except Exception as e:
        return {"error": str(e)}

@app.get("/debug/all_cities")
def debug_all_cities():
    """TÃ¼m ÅŸehirleri ve kayÄ±t sayÄ±larÄ±nÄ± listele"""
    try:
        df_train, df_test = get_processed_frames(target_col="Genel_Toplam_MWh")
        
        # Test verisindeki ÅŸehirler ve kayÄ±t sayÄ±larÄ±
        test_city_counts = df_test[CITY_COL].value_counts().to_dict()
        train_city_counts = df_train[CITY_COL].value_counts().to_dict()
        
        # TÃ¼m ÅŸehirleri bÃ¼yÃ¼k harf yaparak birleÅŸtir
        all_cities = sorted(set(df_test[CITY_COL].dropna().unique()))
        
        city_details = {}
        for city in all_cities:
            city_details[city] = {
                "test_records": test_city_counts.get(city, 0),
                "train_records": train_city_counts.get(city, 0),
                "in_both": city in test_city_counts and city in train_city_counts
            }
        
        return {
            "total_cities": len(all_cities),
            "cities": all_cities,
            "city_details": city_details,
            "summary": {
                "cities_with_0_test_records": [city for city, details in city_details.items() if details["test_records"] == 0],
                "cities_with_1_plus_test_records": [city for city, details in city_details.items() if details["test_records"] > 0],
                "max_records_city": max(city_details.items(), key=lambda x: x[1]["test_records"]) if city_details else None
            }
        }
    except Exception as e:
        return {"error": str(e)}

